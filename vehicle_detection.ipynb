{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ0yefGV0pek"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import argparse\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os.path"
      ],
      "metadata": {
        "id": "n1ZeqRoL0wVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "McdJiTBm0zmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter path for the image to be tested\n",
        "input_path = r'C:\\\\Users\\\\nisha\\\\OneDrive\\\\Desktop\\\\vehicle detection\\\\license.jpg'\n",
        "Image(input_path)"
      ],
      "metadata": {
        "id": "p-LNGFJZ07Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open the image file\n",
        "cap = cv2.VideoCapture(input_path)\n",
        "confThreshold = 0.5  #Confidence threshold\n",
        "nmsThreshold = 0.4  #Non-maximum suppression threshold"
      ],
      "metadata": {
        "id": "wFhTUgZh1E3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inpWidth = 416     #Width of network's input image\n",
        "inpHeight = 416     #Height of network's input image\n",
        "# Load names of classes\n",
        "classesFile = \"C:\\\\Users\\\\nisha\\\\OneDrive\\\\Desktop\\\\vehicle detection\\\\yolo_utils\\\\classes.names\""
      ],
      "metadata": {
        "id": "PSy6n1fq1Icb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append all different classes into the list 'classes'\n",
        "classes = None\n",
        "with open(classesFile, 'rt') as f:\n",
        "    classes = f.read().rstrip('\\n').split('\\n')\n"
      ],
      "metadata": {
        "id": "xiQw8Vdh1NUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give the configuration and weight files for the model and load the network using them.\n",
        "modelConfiguration = \"C:\\\\Users\\\\nisha\\\\OneDrive\\\\Desktop\\\\vehicle detection\\\\yolov3.cfg\"\n",
        "modelWeights = \"C:\\\\Users\\\\nisha\\\\OneDrive\\\\Desktop\\\\vehicle detection\\\\yolov3.weights\"\n",
        "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "# Get the names of the output layers\n",
        "def getOutputsNames(net):\n",
        "    # Get the names of all the layers in the network\n",
        "    layersNames = net.getLayerNames()\n",
        "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
        "    return [layersNames[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Draw the predicted bounding box\n",
        "def drawPred(classId, conf, left, top, right, bottom, frame):\n",
        "    # Draw a bounding box.\n",
        "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
        "\n",
        "    label = '%.2f' % conf\n",
        "\n",
        "    # Get the label for the class name and its confidence\n",
        "    if classes:\n",
        "        assert(classId < len(classes))\n",
        "        label = '%s:%s' % (classes[classId], label)\n",
        "\n",
        "    #Display the label at the top of the bounding box\n",
        "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "    top = max(top, labelSize[1])\n",
        "    cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (0, 0, 255), cv2.FILLED)\n",
        "    #cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine),    (255, 255, 255), cv.FILLED)\n",
        "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 2)\n"
      ],
      "metadata": {
        "id": "aiiWYwbE1Tgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
        "def postprocess(frame, outs):\n",
        "    frameHeight = frame.shape[0]\n",
        "    frameWidth = frame.shape[1]\n",
        "\n",
        "    # Scan through all the bounding boxes output from the network and keep only the\n",
        "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
        "    classIds = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        #print(\"out.shape : \", out.shape)\n",
        "        for detection in out:\n",
        "            #if detection[4]>0.001:\n",
        "            scores = detection[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            #if scores[classId]>confThreshold:\n",
        "            confidence = scores[classId]\n",
        "            '''if detection[4]>confThreshold:\n",
        "                print(detection[4], \" - \", scores[classId], \" - th : \", confThreshold)\n",
        "                print(detection)'''\n",
        "            if confidence > confThreshold:\n",
        "                center_x = int(detection[0] * frameWidth)\n",
        "                center_y = int(detection[1] * frameHeight)\n",
        "                width = int(detection[2] * frameWidth)\n",
        "                height = int(detection[3] * frameHeight)\n",
        "                left = int(center_x - width / 2)\n",
        "                top = int(center_y - height / 2)\n",
        "                classIds.append(classId)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([left, top, width, height])\n",
        "\n",
        "    # Perform non maximum suppression to eliminate redundant overlapping boxes with lower confidences.\n",
        "    cropped=None\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
        "    for i in indices:\n",
        "        #i = i[0]\n",
        "        box = boxes[i]\n",
        "        left = box[0]\n",
        "        top = box[1]\n",
        "        width = box[2]\n",
        "        height = box[3]\n",
        "         # calculate bottom and right\n",
        "        bottom = top + height\n",
        "        right = left + width\n",
        "\n",
        "        #crop the plate out\n",
        "        cropped = frame[top:bottom, left:right].copy()\n",
        "        # drawPred\n",
        "        drawPred(classIds[i], confidences[i], left, top, right, bottom, frame)\n",
        "    if cropped is not None:\n",
        "        return cropped"
      ],
      "metadata": {
        "id": "8rFC4iTD1X-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cv2.waitKey(1) < 0:\n",
        "\n",
        "    hasFrame, frame = cap.read() #frame: an image object from cv2\n",
        "\n",
        "    # Stop the program if reached end of video\n",
        "    if not hasFrame:\n",
        "        print(\"Done processing !!!\")\n",
        "        break\n",
        "\n",
        "    # Create a 4D blob from a frame.\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
        "\n",
        "    # Sets the input to the network\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Runs the forward pass to get output of the output layers\n",
        "    outs = net.forward(getOutputsNames(net))\n",
        "\n",
        "    # Remove the bounding boxes with low confidence\n",
        "    cropped = postprocess(frame, outs)\n",
        "\n",
        "    plt.imshow(frame)\n",
        "    plt.title(\"Predicted License Plate\")\n",
        "    plt.show()\n",
        "    plt.imshow(cropped)\n",
        "    plt.title(\"Cropped Image\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "eVeeki-k1i2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_contours(dimensions, img) :\n",
        "\n",
        "    # Find all contours in the image\n",
        "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Retrieve potential dimensions\n",
        "    lower_width = dimensions[0]\n",
        "    upper_width = dimensions[1]\n",
        "    lower_height = dimensions[2]\n",
        "    upper_height = dimensions[3]\n",
        "\n",
        "    # Check largest 5 or  15 contours for license plate or character respectively\n",
        "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
        "\n",
        "    ii = cv2.imread('contour.jpg')\n",
        "\n",
        "    x_cntr_list = []\n",
        "    target_contours = []\n",
        "    img_res = []\n",
        "    for cntr in cntrs :\n",
        "        # detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
        "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
        "\n",
        "        # checking the dimensions of the contour to filter out the characters by contour's size\n",
        "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
        "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
        "\n",
        "            char_copy = np.zeros((44,24))\n",
        "            # extracting each character using the enclosing rectangle's coordinates.\n",
        "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
        "            char = cv2.resize(char, (20, 40))\n",
        "\n",
        "            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
        "            plt.imshow(ii, cmap='gray')\n",
        "            plt.title('Predict Segments')\n",
        "\n",
        "            # Make result formatted for classification: invert colors\n",
        "            char = cv2.subtract(255, char)\n",
        "\n",
        "            # Resize the image to 24x44 with black border\n",
        "            char_copy[2:42, 2:22] = char\n",
        "            char_copy[0:2, :] = 0\n",
        "            char_copy[:, 0:2] = 0\n",
        "            char_copy[42:44, :] = 0\n",
        "            char_copy[:, 22:24] = 0\n",
        "\n",
        "            img_res.append(char_copy)\n",
        "\n",
        "    plt.show()\n",
        "    # arbitrary function that stores sorted list of character indeces\n",
        "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
        "    img_res_copy = []\n",
        "    for idx in indices:\n",
        "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
        "    img_res = np.array(img_res_copy)\n",
        "\n",
        "    return img_res"
      ],
      "metadata": {
        "id": "L2GP6vU_1oJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def segment_characters(image) :\n",
        "\n",
        "    # Preprocess cropped license plate image\n",
        "    img_lp = cv2.resize(image, (333, 75))\n",
        "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
        "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
        "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
        "\n",
        "    LP_WIDTH = img_binary_lp.shape[0]\n",
        "    LP_HEIGHT = img_binary_lp.shape[1]\n",
        "\n",
        "    # Make borders white\n",
        "    img_binary_lp[0:3,:] = 255\n",
        "    img_binary_lp[:,0:3] = 255\n",
        "    img_binary_lp[72:75,:] = 255\n",
        "    img_binary_lp[:,330:333] = 255\n",
        "\n",
        "    # Estimations of character contours sizes of cropped license plates\n",
        "    dimensions = [LP_WIDTH/6,\n",
        "                       LP_WIDTH/2,\n",
        "                       LP_HEIGHT/10,\n",
        "                       2*LP_HEIGHT/3]\n",
        "    plt.imshow(img_binary_lp, cmap='gray')\n",
        "    plt.title('Contour')\n",
        "    plt.show()\n",
        "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
        "\n",
        "    # Get contours within cropped license plate\n",
        "    char_list = find_contours(dimensions, img_binary_lp)\n",
        "\n",
        "    return char_list\n"
      ],
      "metadata": {
        "id": "lTOeE_7k1yqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cv2.waitKey(1) < 0:\n",
        "\n",
        "    hasFrame, frame = cap.read() #frame: an image object from cv2\n",
        "\n",
        "    # Stop the program if reached end of video\n",
        "    if not hasFrame:\n",
        "        print(\"Done processing !!!\")\n",
        "        break\n",
        "\n",
        "    # Create a 4D blob from a frame.\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
        "\n",
        "    # Sets the input to the network\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Runs the forward pass to get output of the output layers\n",
        "    outs = net.forward(getOutputsNames(net))\n",
        "\n",
        "    # Remove the bounding boxes with low confidence\n",
        "    cropped = postprocess(frame, outs)\n"
      ],
      "metadata": {
        "id": "JTZZHy7q2M93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char=segment_characters(cropped)\n",
        "for i in range(len(char)):\n",
        "    plt.subplot(1, len(char), i+1)\n",
        "    plt.imshow(char[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tvzrQw9D2Qba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = Sequential()\n",
        "loaded_model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "loaded_model.add(Dropout(0.4))\n",
        "loaded_model.add(Flatten())\n",
        "loaded_model.add(Dense(128, activation='relu'))\n",
        "loaded_model.add(Dense(36, activation='softmax'))\n",
        "\n",
        "# Restore the weights\n",
        "loaded_model.load_weights('checkpoints/my_checkpoint')\n"
      ],
      "metadata": {
        "id": "dgI9q_YE2TxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_dimension(img):\n",
        "    new_img = np.zeros((28,28,3))\n",
        "    for i in range(3):\n",
        "        new_img[:,:,i] = img\n",
        "        return new_img\n",
        "\n",
        "def show_results():\n",
        "    dic = {}\n",
        "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "    for i,c in enumerate(characters):\n",
        "        dic[i] = c\n",
        "\n",
        "    output = []\n",
        "    for i,ch in enumerate(char): #iterating over the characters\n",
        "        img_ = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
        "        img = fix_dimension(img_)\n",
        "        img = img.reshape(1,28,28,3) #preparing image for the model\n",
        "        y_ = loaded_model.predict_classes(img)[0] #predicting the class\n",
        "        character = dic[y_]\n",
        "        output.append(character) #storing the result in a list\n",
        "\n",
        "    plate_number = ''.join(output)\n",
        "\n",
        "    return plate_number\n"
      ],
      "metadata": {
        "id": "gjBzA7-211PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(show_results())\n",
        "# Segmented characters and their predicted value.\n",
        "plt.figure(figsize=(10,6))\n",
        "for i,ch in enumerate(char):\n",
        "    img = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
        "    plt.subplot(3,4,i+1)\n",
        "    plt.imshow(img,cmap='gray')\n",
        "    plt.title(f'predicted: {show_results()[i]}')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8ir2u_uc2dFy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}